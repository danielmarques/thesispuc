\chapter{Trabalhos Relacionados}
\label{chap:trabalhosrelacionados}

A \textit{Classificação em Múltiplas Classes} representa um importante subgrupo das tarefas de classificação abordadas pelo aprendizado de máquina.
Diferente dos problemas clássicos de classificação, neste caso cada instância está associada à mais de uma classe \cite{Tsoumakas}.
Além disso, é possível que as classes tenham correlações entre si de forma a influenciar no resultado final, aumentando a dificuldade da tarefa.
De maneira formal, a tarefa de classificação em múltiplas classes requer que o vetor de atributos de entrada \textit{x} seja mapeado em um vetor de saída \textit{y} com valores binários que representam as classes.
Isto é, \textit{x} é da forma $[a_1, a_2, ..., a_n]$, onde $a_j$ representa um dos n atributos, e \textit{y} da forma $[c_1, c_2, ... , c_k]$ onde $c_j$ pode assumir o valor zero ou um, indicando se aquela classe está relacionada à instância.  

O método proposto nesta dissertação figura entre diversos outros que procuram solucionar problemas de classificação em múltiplas classes.
Ainda mais especificamente aqueles voltados para \textit{ranking}, que é uma das tarefas cada vez mais proeminentes em aprendizado supervisionado.

\section{Métodos de Transformação do Problema}

Entre as soluções encontradas na literatura podemos destacar ainda aquelas que fazem a transformação do problema \cite{Tsoumakas}.
Isto é, elas executam uma transformação do problema de classificação em múltiplas classes de forma que ele possa ser solucionado com uma ou mais classificações em uma classe.
Como o método proposto nesta dissertação também se baseia em transformação do problema (filtragens sucessivas do conjunto de dados), a seguir apresentaremos alguns destes métodos.

\subsection{Métodos Clássicos}

O método de transformação de problema mais famoso é chamado de \textit{Binary Relevance} \cite{Tsoumakas, Godbole, Zhang}.
Este método se baseia em transformar um problema de classificação em múltiplas classes em diversos problemas de classificação binários.
Ou seja, se existem $\vert L \vert$ classes diferentes no conjunto de dados, $\vert L \vert$ classificadores diferentes são treinados.
Cada um deles é responsável pela classificação binária referente à uma das $\vert L \vert$ classes do conjunto de dados.
Note porém que este método não é capaz de modelar qualquer tipo de correlação entre as classes, portanto não pode ser usado para gerar listas ordenadas por relevância.

\textit{Label Powerset} é mais um método clássico encontrado na literatura \cite{Tsoumakas02, Read02}.
Este método se baseia em transformar cada possível combinação entre as $\vert L \vert$ classes em novas classes atômicas.
Com isso o problema pode ser resolvido por um classificador para múltiplas classes comum.
Além disso, este método leva diretamente em consideração a correlação entre classes.
Todavia, a desvantagem do \textit{Label Powerset} é sua complexidade de tempo no pior caso.

\subsection{Outros Métodos}

O método denominado \textit{RAkEL} (\textit{RAndom k labELsets}) é baseado em \textit{Label Powerset} \cite{Tsoumakas03}.
Sua proposta é segmentar aleatoriamente o conjunto de dados de acordo com as classes.
Desta forma diversos subgrupos menores (\textit{labelsets}) podem ser criados.
Estes subgrupos também podem ou não ter classes em comum.
Um classificador é treinado para cada subgrupo utilizando o método \textit{Label Powerset} citado anteriormente.
Para classificar uma nova instância o método combina os resultados de todos os classificadores.

Existem diversos métodos que transformam um conjunto de dados com múltiplas classes por exemplo em outro com uma única classe por exemplo \cite{Boutell, Chen}.
Nestes métodos a proposta é que cada exemplo (x,Y) seja decomposto em $\vert Y \vert$ exemplos (x, l) onde $l \in Y$.
Com isso um único classificador probabilístico pode ser treinado por meio do conjunto de dados transformado.
É possível então classificar uma nova instância a partir da distribuição de probabilidades devolvida por tal classificador.
As classes pertinentes podem ser selecionadas entre aquelas com probabilidade superior a um dado patamar, e.g. 50 \%.

Entre os modelos de transformação de problema também podemos citar o de classificadores em cascata \cite{Read}. 
No caso de um conjunto de dados D com $\vert L \vert$ valores de classe diferentes, $\vert L \vert$ classificadores são utilizados em cascata. 
O conjunto de dados de cada classificador é acrescido sucessivamente de um novo atributo binário, que informa o resultado do classificador anterior. 
Com isso os classificadores em cascata são capazes de utilizar, em certo nível, a informação de interdependência entre classes. 
Notadamente, a ordem dos classificadores impacta na acurácia final.
Para resolver este problema o artigo introduz o esquema de conjuntos de classificadores em cascata. 
Neste caso, subconjuntos aleatórios de D são utilizados para treinar cada classificador. 
Além disso, cada classificador é treinado com uma ordem aleatória de classes. 
Ao classificar um novo exemplo a lista de saída é dada pela votação por comitê. 
Desta forma o conjunto de classificadores em cascata é capaz de gerar um ranking diretamente.

\textit{Ranking by pairwise comparison} é um método que transforma um conjunto de dados com múltiplas classes em diversos conjuntos de dados com a classe binária \cite{Hullermeier, Mencia, Furnkranz}.
Um novo conjunto é criado para cada par de classes do conjunto de dados original.
Este encorpora os exemplos que contemplam uma classe ou a outra, mas não as duas.
Um classificador binário é então treinado para cada um desses conjuntos no intuito de aprender a diferenciar entre as duas classes em questão.
Por fim, esses classificadores são empregados em conjunto para gerar a lista ordenada de saída referente à uma nova instância.


%	Métodos para ranking?
%	Label Rankings ?
